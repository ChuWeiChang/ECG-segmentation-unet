{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1640243035820,
     "user": {
      "displayName": "nn drdr",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00449971236444382255"
     },
     "user_tz": -480
    },
    "id": "a2t4Kg1-VCLX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input, concatenate, UpSampling2D, Reshape, core\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1640243050906,
     "user": {
      "displayName": "nn drdr",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00449971236444382255"
     },
     "user_tz": -480
    },
    "id": "UIgTWkGXKkFy"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load_images_from_folder(path):\n",
    "  i=0\n",
    "  image = []\n",
    "  mask = []\n",
    "  files= os.listdir(path) #得到資料夾下的所有檔名稱\n",
    "  Resize= (512,512)\n",
    "  for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "      fullpath = os.path.join(root, file)\n",
    "      img = np.array(cv2.imread(fullpath)) \n",
    "      if file==\"img.png\":\n",
    "        img = cv2.resize(img, Resize, interpolation=cv2.INTER_AREA)\n",
    "        image.append(img)\n",
    "      elif file==\"label.png\":\n",
    "        img = cv2.resize(img, Resize, interpolation=cv2.INTER_AREA)\n",
    "        mask.append(img)\n",
    "      i+=1\n",
    "      if(i%50==0):\n",
    "        print(i)\n",
    "  image = np.array(image).astype(\"float32\")/255\n",
    "  mask = np.array(mask).astype(\"float32\")/255\n",
    "  return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1640243051320,
     "user": {
      "displayName": "nn drdr",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00449971236444382255"
     },
     "user_tz": -480
    },
    "id": "AlMlqvlg4A-5"
   },
   "outputs": [],
   "source": [
    "def unet(Inshape):\n",
    "    from keras import losses\n",
    "    inputs = Input(shape=Inshape)\n",
    "    conv1 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #512\n",
    "    conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #256\n",
    "    conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #128\n",
    "    conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    #128\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    #64\n",
    "    conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    #64\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(3, (3, 3), activation = 'relu', padding = 'same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = core.Activation('softmax')(conv9)\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer=SGD(learning_rate=0.01, momentum= 0.9), loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230221,
     "status": "ok",
     "timestamp": 1640243282754,
     "user": {
      "displayName": "nn drdr",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00449971236444382255"
     },
     "user_tz": -480
    },
    "id": "IoqyreoJKukp",
    "outputId": "04b2ea96-62b2-490d-be8e-5da34edab3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "dir_train = \"./EKG_seg/train\"#training\n",
    "img, mask = load_images_from_folder(dir_train)\n",
    "dir_validation =\"./EKG_seg/validation\"\n",
    "V_img, V_mask =  load_images_from_folder(dir_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5249104,
     "status": "ok",
     "timestamp": 1640248531855,
     "user": {
      "displayName": "nn drdr",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00449971236444382255"
     },
     "user_tz": -480
    },
    "id": "xejXHBb_p61Y",
    "outputId": "c0e966c8-a1a5-4f86-fba9-b5bdfd422e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "44/44 [==============================] - 248s 5s/step - loss: 0.0728 - accuracy: 0.3290 - val_loss: 0.0614 - val_accuracy: 0.0949\n",
      "Epoch 2/30\n",
      "44/44 [==============================] - 171s 4s/step - loss: 0.0648 - accuracy: 0.1727 - val_loss: 0.0619 - val_accuracy: 0.0288\n",
      "Epoch 3/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0600 - accuracy: 0.2215 - val_loss: 0.0622 - val_accuracy: 0.0288\n",
      "Epoch 4/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0565 - accuracy: 0.3099 - val_loss: 0.0622 - val_accuracy: 0.0288\n",
      "Epoch 5/30\n",
      "44/44 [==============================] - 171s 4s/step - loss: 0.0539 - accuracy: 0.2506 - val_loss: 0.0622 - val_accuracy: 0.0288\n",
      "Epoch 6/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0502 - accuracy: 0.2383 - val_loss: 0.0622 - val_accuracy: 0.0289\n",
      "Epoch 7/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0489 - accuracy: 0.2539 - val_loss: 0.0621 - val_accuracy: 0.0310\n",
      "Epoch 8/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0472 - accuracy: 0.2730 - val_loss: 0.0619 - val_accuracy: 0.0897\n",
      "Epoch 9/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0481 - accuracy: 0.2844 - val_loss: 0.0588 - val_accuracy: 0.0664\n",
      "Epoch 10/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0463 - accuracy: 0.3039 - val_loss: 0.0537 - val_accuracy: 0.0916\n",
      "Epoch 11/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0454 - accuracy: 0.2551 - val_loss: 0.0505 - val_accuracy: 0.0947\n",
      "Epoch 12/30\n",
      "44/44 [==============================] - 171s 4s/step - loss: 0.0481 - accuracy: 0.3034 - val_loss: 0.0412 - val_accuracy: 0.1108\n",
      "Epoch 13/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0461 - accuracy: 0.3069 - val_loss: 0.0385 - val_accuracy: 0.1190\n",
      "Epoch 14/30\n",
      "44/44 [==============================] - 171s 4s/step - loss: 0.0451 - accuracy: 0.2710 - val_loss: 0.0374 - val_accuracy: 0.1240\n",
      "Epoch 15/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0467 - accuracy: 0.2821 - val_loss: 0.0385 - val_accuracy: 0.1120\n",
      "Epoch 16/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0442 - accuracy: 0.2520 - val_loss: 0.0407 - val_accuracy: 0.1105\n",
      "Epoch 17/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0447 - accuracy: 0.3579 - val_loss: 0.0472 - val_accuracy: 0.0949\n",
      "Epoch 18/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0442 - accuracy: 0.2934 - val_loss: 0.0378 - val_accuracy: 0.1116\n",
      "Epoch 19/30\n",
      "44/44 [==============================] - 171s 4s/step - loss: 0.0438 - accuracy: 0.3655 - val_loss: 0.0406 - val_accuracy: 0.1083\n",
      "Epoch 20/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0449 - accuracy: 0.3280 - val_loss: 0.0410 - val_accuracy: 0.1089\n",
      "Epoch 21/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0453 - accuracy: 0.3061 - val_loss: 0.0400 - val_accuracy: 0.1082\n",
      "Epoch 22/30\n",
      "44/44 [==============================] - 171s 4s/step - loss: 0.0436 - accuracy: 0.3337 - val_loss: 0.0419 - val_accuracy: 0.1017\n",
      "Epoch 23/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0436 - accuracy: 0.3074 - val_loss: 0.0370 - val_accuracy: 0.1089\n",
      "Epoch 24/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0449 - accuracy: 0.4170 - val_loss: 0.0385 - val_accuracy: 0.1102\n",
      "Epoch 25/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0434 - accuracy: 0.3874 - val_loss: 0.0384 - val_accuracy: 0.1164\n",
      "Epoch 26/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0441 - accuracy: 0.3867 - val_loss: 0.0393 - val_accuracy: 0.1084\n",
      "Epoch 27/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0441 - accuracy: 0.3507 - val_loss: 0.0387 - val_accuracy: 0.1103\n",
      "Epoch 28/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0427 - accuracy: 0.2978 - val_loss: 0.0381 - val_accuracy: 0.1114\n",
      "Epoch 29/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0433 - accuracy: 0.3525 - val_loss: 0.0420 - val_accuracy: 0.1029\n",
      "Epoch 30/30\n",
      "44/44 [==============================] - 170s 4s/step - loss: 0.0446 - accuracy: 0.4435 - val_loss: 0.0441 - val_accuracy: 0.0959\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "IN = (img.shape[1],img.shape[2],img.shape[3])\n",
    "model = unet(IN)\n",
    "history = model.fit(img, mask,  epochs= 30, batch_size=4,validation_data = (V_img, V_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1763082,
     "status": "ok",
     "timestamp": 1640251844559,
     "user": {
      "displayName": "nn drdr",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00449971236444382255"
     },
     "user_tz": -480
    },
    "id": "jvOEun0blEOp",
    "outputId": "2cd4b00d-d306-4c50-90ef-b80ba79c05b7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 175s 4s/step - loss: 0.0427 - accuracy: 0.3485 - val_loss: 0.0423 - val_accuracy: 0.1007\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0413 - accuracy: 0.3945 - val_loss: 0.0406 - val_accuracy: 0.1035\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0434 - accuracy: 0.4013 - val_loss: 0.0344 - val_accuracy: 0.1280\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0431 - accuracy: 0.3299 - val_loss: 0.0377 - val_accuracy: 0.1098\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0438 - accuracy: 0.3900 - val_loss: 0.0385 - val_accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0434 - accuracy: 0.4070 - val_loss: 0.0404 - val_accuracy: 0.1034\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0426 - accuracy: 0.3535 - val_loss: 0.0401 - val_accuracy: 0.1049\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0418 - accuracy: 0.3914 - val_loss: 0.0408 - val_accuracy: 0.1072\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0423 - accuracy: 0.3535 - val_loss: 0.0378 - val_accuracy: 0.1071\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 176s 4s/step - loss: 0.0412 - accuracy: 0.4051 - val_loss: 0.0360 - val_accuracy: 0.1134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa707e0da10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img, mask,  epochs= 10, batch_size=4,validation_data = (V_img, V_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model1.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECG Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
